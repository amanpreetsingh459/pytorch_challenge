{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring your trained model\n",
    "\n",
    "In the cell below, please load your model into `model`. Also if you used an image size for your input images that *isn't* 224x224, you'll need to set `image_size` to the size you used. The scoring code assumes square input images.\n",
    "\n",
    "For example, this is how I loaded in my checkpoint:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class FFClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_features, \n",
    "                       out_features, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(p=drop_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def load_checkpoint(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    model = models.vgg16(pretrained=False)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Put the classifier on the pretrained network\n",
    "    model.classifier = FFClassifier(25088, checkpoint['hidden'], 102)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('/home/workspace/classifier.pt')\n",
    "```\n",
    "\n",
    "Your exact code here will depend on how you defined your network in the project. Make sure you use the absolute path to your checkpoint which should have been uploaded to the `/home/workspace` directory.\n",
    "\n",
    "Run the cell, then after loading the data, press \"Test Code\" below. This can take a few minutes or more depending on the size of your network. Your model needs  to reach **at least 20% accuracy** on the test set to be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==0.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-0.4.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check version\n",
    "!pip install torch==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.torch/models/resnet152-b121ed2d.pth\n",
      "100%|██████████| 241530880/241530880 [00:15<00:00, 15237892.98it/s]\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.torch/models/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 574673361/574673361 [00:49<00:00, 12036216.15it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.torch/models/densenet161-8d451a50.pth\n",
      "100%|██████████| 115730790/115730790 [00:04<00:00, 23977525.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load and Modify Models\n",
    "\n",
    "resnet152 = models.resnet152(pretrained=True)\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "densenet161 = models.densenet161(pretrained=True)\n",
    "\n",
    "# Add attributes to models\n",
    "resnet152.name = 'ResNet_152'\n",
    "resnet152.last_layer_attr = 'fc'\n",
    "\n",
    "vgg19.name = 'VGG_19'\n",
    "vgg19.last_layer_attr = 'classifier'\n",
    "\n",
    "densenet161.name = 'DenseNet_161'\n",
    "densenet161.last_layer_attr = 'classifier'\n",
    "\n",
    "# List of Models and its last layer\n",
    "transfer_models = [resnet152,\n",
    "                    vgg19,\n",
    "                    densenet161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_152: Linear(in_features=2048, out_features=102, bias=True)\n",
      "VGG_19: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=102, bias=True)\n",
      ")\n",
      "DenseNet_161: Linear(in_features=2208, out_features=102, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Re-defines last layers\n",
    "def redefine_last_layer(model, n_inputs, n_outputs):\n",
    "    \"\"\"\n",
    "    Changes models last layer.\n",
    "    \"\"\"\n",
    "    # Check if returns a list\n",
    "    attr = getattr(model, model.last_layer_attr)\n",
    "    if isinstance(attr, nn.Sequential):\n",
    "        attr[-1] = nn.Linear(n_inputs, n_outputs)\n",
    "    else:\n",
    "        attr = nn.Linear(n_inputs, n_outputs)\n",
    "    \n",
    "    # Modifies last layer attributes\n",
    "    setattr(model, model.last_layer_attr, attr)\n",
    "\n",
    "# For all models\n",
    "for model in transfer_models:\n",
    "    try:\n",
    "        n_in = getattr(model, model.last_layer_attr).in_features\n",
    "    except AttributeError:\n",
    "        n_in = getattr(model, model.last_layer_attr)[-1].in_features\n",
    "    n_out = 102\n",
    "    redefine_last_layer(model, n_in, n_out)\n",
    "    print(model.name + \": \" + str(getattr(model, model.last_layer_attr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads a checkpoint and rebuilds the model\n",
    "def load_model(filepath):\n",
    "    \"\"\"\n",
    "    Loads models from transfer learning.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(filepath, map_location='cpu')\n",
    "    if 'VGG_19' in filepath:\n",
    "        model = vgg19\n",
    "    elif 'DenseNet_161' in filepath:\n",
    "        model = densenet161\n",
    "    elif 'ResNet_152' in filepath:\n",
    "        model = resnet152\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    model.idx_to_class = {idx:class_ for class_, idx in model.class_to_idx.items()}\n",
    "    model.name = checkpoint['name']\n",
    "    model.optimizer_state  = checkpoint['optimizer_state']\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "vriua3cwbv"
   },
   "outputs": [],
   "source": [
    "# Load your model to this variable\n",
    "model = load_model('checkpoint_ResNet_152.pth')\n",
    "   \n",
    "# If you used something other than 224x224 cropped images, set the correct size here\n",
    "image_size = 224\n",
    "# Values you used for normalizing the images. Default here are for \n",
    "# pretrained models from torchvision.\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cell_exec_timeout": 600,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
